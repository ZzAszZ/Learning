1. Что такое BIG O и как происходит оценка Асимптотической сложности алгоритмов?
    Нотация Big-O-это метрика, используемая для определения сложности алгоритма. В принципе, обозначение Big-O означает
    связь между входными данными алгоритма и шагами, необходимыми для выполнения алгоритма. Он обозначается большой
    буквой “О”, за которой следуют открывающая и закрывающая скобки. Внутри круглой скобки связь между входными данными
    и шагами, выполняемыми алгоритмом, представлена с помощью буквы “n”.

    Определяя асимптотическую сложность алгоритма, мы отбрасываем члены меньшего порядка суммы, которые при больших n
    становятся малыми, по сравнению с другими слагаемыми. Пример. Если временная сложность алгоритма описывается как
    T (n) = 4n2 + 7n + 12, то вычислительная сложность определяется, как O (n2).


2.Что такое рекурсия? Сравните преимущества и недостатки интеративных и рекурсивных алгоритмов. Пример.

    Рекурсия — это функция, которая вызывает саму себя, но с другими значениями параметров.

    На самом деле понятия рекурсии и процесса никак не связаны. Рекурсия — просто абстрактная концепция, которую можно
    наблюдать в природе, в математике и в других областях. Такая же абстрактная, как, например, музыкальная гармония.

    -Рекурсивный процесс на каждом шаге рекурсии говорит «я это запомню и потом посчитаю». «Потом» наступает в самом конце.

    Если рекурсивный процесс считает факториал 6, то ему нужно запомнить 5 чисел, чтобы посчитать их в самом конце,
     когда уже никуда не деться и рекурсивно двигаться вниз больше нельзя
    Когда мы находимся в очередном вызове функции, то где-то снаружи этого вызова в памяти хранятся эти запомненные
    числа

    На этой картинке видно, как растет использование памяти: процессу нужно запоминать все больше и больше чисел



    -Рекурсивный процесс — это процесс с отложенным вычислением.

    Итеративный процесс постоянно говорит «я сейчас посчитаю все что можно и продолжу» на каждом шаге рекурсии.
    Ему не нужно ничего запоминать вне вызова, он всегда все считает в первый возможный момент. Каждый шаг рекурсии
    может существовать в изоляции от прошлых, потому что вся информация передается последовательно.

    Когда итеративный процесс считает факториал 6, то ему не нужно запоминать числа. Нужно лишь считать и передавать
    результат дальше, в новый вызов
    Когда мы находимся в очередном вызове функции, снаружи этого вызова в памяти ничего не нужно запоминать

    А на этой картинке видно, что использование памяти не растет.



    Что такое хвостовая рекурсия
    Как использовать преимущества итеративного процесса и одновременно избавиться от недостатка рекурсивных
    функций, то есть от неумолимого роста использования памяти? Можно избавить процесс от заполнения стека
    «ненужными» контекстами предыдущих вызовов и обеспечить прямой возврат из функции при достижении терминального условия.

    Для этого служит так называемая оптимизация хвостовой рекурсии (Tail call optimization). Итеративный процесс,
    который мы рассмотрели, как раз можно отнести к хвостовой рекурсии. Благодаря оптимизации состояния стека,
    она придает итеративному процессу вид «плоской» итерации. Так исключается его переполнение из-за большой глубины рекурсии.

    Хвостовая рекурсия и ее оптимизация широко используется при написании программ на функциональных языках программирования.




3. Что такое жадные алгоритмы. Пример.
    Итак, жадный алгоритм (greedy algorithm) — это алгоритм, который на каждом шагу делает локально наилучший выбор
    в надежде, что итоговое решение будет оптимальным.


4.Раскажите про пузырьковую сортировку.
     Принцип действий прост: обходим массив от начала до конца, попутно меняя местами неотсортированные соседние элементы.
     В результате первого прохода на последнее место «всплывёт» максимальный элемент. Теперь снова обходим
     неотсортированную часть массива (от первого элемента до предпоследнего) и меняем по пути неотсортированных
     соседей. Второй по величине элемент окажется на предпоследнем месте. Продолжая в том же духе, будем обходить
     всё уменьшающуюся неотсортированную часть массива, запихивая найденные максимумы в конец.

     Сложность квадратичная.


5.Быстрая сортировка.
    Алгоритм быстрой сортировки является рекурсивным, поэтому для простоты процедура на вход будет принимать границы
    участка массива от l включительно и до r не включительно. Понятно, что для того, чтобы отсортировать весь массив,
    в качестве параметра l надо передать 0, а в качестве r — n, где по традиции n обозначает длину массива.

    В основе алгоритма быстрой сортировке лежит процедура partition. Partition выбирает некоторый элемент массива и
    переставляет элементы участка массива таким образом, чтобы массив разбился на 2 части: левая часть содержит элементы,
    которые меньше этого элемента, а правая часть содержит элементы, которые больше или равны этого элемента.
    Такой разделяющий элемент называется пивотом.


    Пивот в нашем случае выбирается случайным образом. Такой алгоритм называется рандомизированным. На самом деле
    пивот можно выбирать самым разным образом: либо брать случайный элемент, либо брать первый / последний элемент
    учаcтка, либо выбирать его каким-то «умным» образом. Выбор пивота является очень важным для итоговой сложности
    алгоритма сортировки, но об этом несколько позже. Сложность же процедуры partition — O(n),
    где n = r — l — длина участка.

    О(

    Если прогнать написанную сортировку на примере массива 1 2 2, то можно заметить,
    что она никогда не закончится. Почему так получилось?



6.Сортировка слиянием.

    Сортировки слиянием работают по такому принципу:

    Ищутся (как вариант — формируются) упорядоченные подмассивы.
    Упорядоченные подмассивы соединяются в общий упорядоченный подмассив.

    Сам по себе какой-нибудь упорядоченный подмассив внутри массива не имеет особой ценности. Но если в массиве мы
    найдём два упорядоченных подмассива, то это совершенно другое дело. Дело в том, что очень быстро и с
    минимальными затратами можно произвести над ними слияние — сформировать из пары упорядоченных подмассивов общий
    упорядоченный подмассив.

    Как видите, объединить два упорядоченных массива в один не просто, а очень просто.
    Нужно двигаться одновременно в обоих массивах слева-направо и сравнивать очередные пары элементов из
    обоих массивов. Меньший элемент отправляется в общий котёл. Когда в одном из массивов элементы заканчиваются,
    оставшиеся элементы из другого массива просто по порядку переносятся в главный список.

    n*logN



7.Бинарное дерево.

    Бинарное дерево — это иерархическая структура данных, в которой каждый узел имеет значение
    (оно же является в данном случае и ключом) и ссылки на левого и правого потомка. Узел, находящийся на
    самом верхнем уровне (не являющийся чьим либо потомком) называется корнем. Узлы, не имеющие потомков
    (оба потомка которых равны NULL) называются листьями.


8.Красно черное дерево.
    Красно-чёрное дерево (англ. red-black tree, RB tree) — один из видов самобалансирующихся двоичных деревьев поиска,
    гарантирующих логарифмический рост высоты дерева от числа узлов и позволяющее быстро выполнять основные операции
    дерева поиска: добавление, удаление и поиск узла. Сбалансированность достигается за счёт введения дополнительного
    атрибута узла дерева — «цвета». Этот атрибут может принимать одно из двух возможных значений — «чёрный» или «красный».

9.Линейный и бинарный поиск.

    Бинарный (двоичный, дихотомический) поиск – это поиск заданного элемента на упорядоченном множестве, осуществляемый
    путем неоднократного деления этого множества на две части таким образом, что искомый элемент попадает в одну из этих
     частей. Поиск заканчивается при совпадении искомого элемента с элементом, который является границей между частями
     множества или при отсутствии искомого элемента.
    найдено на intuit.ru
    Линейный поиск. Линейный, последовательный поиск — алгоритм нахождения заданного значения произвольной функции на
     некотором отрезке. Данный алгоритм является простейшим алгоритмом поиска и, в отличие, например, от двоичного
     поиска, не накладывает никаких ограничений на функцию и имеет простейшую реализацию.


10. Очередь и стек.
    Очередь – это структура данных, представляющая собой последовательность элементов, образованная в порядке их
    поступления.
    Стек – это структура данных, в которой новый элемент всегда записывается в ее начало (вершину)
    и очередной читаемый элемент также всегда выбирается из ее начала. Краткие итоги.
    Стек и очередь – это частные случаи линейного списка.


11. Сравнить сложности вставки и удаления, поиска, доступа по индексу, ArrayList and LinkedList.

    Когда использовать LinkedList:
    1. Необходимо много данных добавлять в начало списка
    2. Удалять с начала (index = 0) списка, т.е. элементы, которые были добавлены первыми.
    3. .set в конце списка

    Когда использовать ArrayList
    1. .get
    2. .set (начало и середина)
    3. .add
    4. remove ( кроме начала списка )


    Выходные данные
    ==============Add====================
    ---Add elements ( 6kk )
    LinkedList: 2264 ms
    ArrayList: 493 ms
    ArrayList is faster

    ==============Insert=================
    ---Insert elements to begin( 100k )
    LinkedList: 132 ms
    ArrayList: 2742 ms
    LinkedList is faster

    ---Insert elements to middle( 60k )
    LinkedList: 4110 ms
    ArrayList: 494 ms
    ArrayList is faster

    ==============Remove=================
    ---Remove elements from begin ( 100k )
    LinkedList: 2 ms
    ArrayList: 3220 ms
    LinkedList is faster

    ---Remove elements from middle ( 100k )
    LinkedList: 7519 ms
    ArrayList: 1544 ms
    ArrayList is faster

    ---Remove elements from end ( 1kk )
    LinkedList: 37 ms
    ArrayList: 8 ms
    ArrayList is faster

    ==============Get====================
    ---Get elements from begin ( 4kk )
    LinkedList: 25 ms
    ArrayList: 7 ms
    ArrayList is faster

    ---Get elements from middle ( 40k )
    LinkedList: 2320 ms
    ArrayList: 0 ms
    ArrayList is faster

    ---Get elements from end ( 3kk )
    LinkedList: 23 ms
    ArrayList: 5 ms
    ArrayList is faster

    ==============Set====================
    ---Set elements at begin ( 1kk )
    LinkedList: 342 ms
    ArrayList: 12 ms
    ArrayList is faster

    ---Set elements at middle ( 50k )
    LinkedList: 3734 ms
    ArrayList: 1 ms
    ArrayList is faster

    ---Set elements at end ( 3kk )
    LinkedList: 40 ms
    ArrayList: 267 ms
    LinkedList faster

    ==============Finish=================